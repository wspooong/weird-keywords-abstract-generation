{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_networkx_graph(filepath: str):\n",
    "    raw_data = json.load(open(filepath))\n",
    "    keywords_list = [x[\"keywords\"][\"chi\"] for x in raw_data if x[\"keywords\"][\"chi\"]]\n",
    "    combinations_list = [list(itertools.combinations(sorted(x), 2)) for x in keywords_list]\n",
    "    nodes_temp = {}\n",
    "    edges_temp = {}\n",
    "\n",
    "    i = 0\n",
    "    for combinations in combinations_list:\n",
    "        for edge in combinations:\n",
    "            for node in edge:\n",
    "                if node not in nodes_temp:\n",
    "                    nodes_temp[node] = {\"count\": 1, \"id\": i}\n",
    "                    i += 1\n",
    "                else:\n",
    "                    nodes_temp[node][\"count\"] += 1\n",
    "        if edge not in edges_temp:\n",
    "            edges_temp[edge] = {\"count\": 1}\n",
    "        else:\n",
    "            edges_temp[edge][\"count\"] += 1\n",
    "\n",
    "    edges = [{\"source_name\": edge[0], \"source\": nodes_temp[edge[0]][\"id\"], \"target_name\": edge[1], \"target\": nodes_temp[edge[1]][\"id\"], \"edge_freq\": edges_temp[edge][\"count\"]} for edge in edges_temp.keys() if edges_temp[edge][\"count\"] > 1]\n",
    "    edges.sort(key=lambda x: x[\"edge_freq\"], reverse=True)\n",
    "    nodes_in_edges = list(itertools.chain(*[[edge[\"source\"], edge[\"target\"]] for edge in edges]))\n",
    "    nodes = [{\"id\": nodes_temp[node][\"id\"], \"name\": node, \"count\": nodes_temp[node][\"count\"]} for node in nodes_temp.keys() if nodes_temp[node][\"id\"] in nodes_in_edges]\n",
    "\n",
    "    nodes_df = pd.DataFrame(nodes)\n",
    "    edges_df = pd.DataFrame(edges)\n",
    "    G = nx.from_pandas_edgelist(edges_df, source=\"source\", target=\"target\", edge_attr=\"edge_freq\", create_using=nx.Graph)\n",
    "    return G, nodes_df, edges_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_communities(G, nodes_df):\n",
    "    def community_allocation(source_val):\n",
    "        for k,v in communities_dict.items():\n",
    "            if source_val in v:\n",
    "                return k\n",
    "    communities = nx.algorithms.community.greedy_modularity_communities(G, weight=\"edge_freq\")\n",
    "    communities_dict = {}\n",
    "    nodes_in_community = [list(i) for i in communities]\n",
    "\n",
    "    for i in nodes_in_community:\n",
    "        communities_dict[nodes_in_community.index(i)] = i\n",
    "\n",
    "    community = nodes_df['id'].map(lambda x: community_allocation(x))\n",
    "    return community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_community_mean_shortest_path(G, nodes_df, community1, community2):\n",
    "    \"\"\"Get the mean shortest path between two communities\"\"\"\n",
    "    def get_shortest_path(node1, node2):\n",
    "        try:\n",
    "            return nx.shortest_path_length(G, node1, node2)\n",
    "        except nx.NetworkXNoPath:\n",
    "            return 0\n",
    "    commu_1 = nodes_df.query(f\"community == {community1}\")[\"id\"].tolist()\n",
    "    commu_2 = nodes_df.query(f\"community == {community2}\")[\"id\"].tolist()\n",
    "\n",
    "    combinations = list(itertools.product(commu_1, commu_2))\n",
    "\n",
    "    return np.mean([get_shortest_path(x[0], x[1]) for x in combinations])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_keywords_generator(nodes_df, community, n=3):\n",
    "    \"\"\"Generate random keywords based on the community\"\"\"\n",
    "    community_nodes = nodes_df.query(f\"community == {community}\")[\"name\"].tolist()\n",
    "    random_keywords = np.random.choice(community_nodes, n)\n",
    "    return random_keywords.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, nodes_df, edges_df = make_networkx_graph(\"data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df[\"community\"] = get_communities(G, nodes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out communities with more than 5 nodes\n",
    "community_list = nodes_df.groupby(\"community\").filter(lambda x: len(x) > 5)[\"community\"].unique().tolist()\n",
    "community_list = sorted(community_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>community1</th>\n",
       "      <th>community2</th>\n",
       "      <th>mean_shortest_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>14.256757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>14.042471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12.890090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>12.517626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12.488641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     community1  community2  mean_shortest_path\n",
       "0             6          17           14.256757\n",
       "1             6          18           14.042471\n",
       "2             6           7           12.890090\n",
       "3             5           6           12.517626\n",
       "4             0           6           12.488641\n",
       "..          ...         ...                 ...\n",
       "271          20          22            0.000000\n",
       "272          20          23            0.000000\n",
       "273          21          22            0.000000\n",
       "274          21          23            0.000000\n",
       "275          22          23            0.000000\n",
       "\n",
       "[276 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix Get the mean shortest path between two communities\n",
    "community_combinations = list(itertools.combinations(community_list, 2))\n",
    "community_combinations = [(x[0], x[1], get_community_mean_shortest_path(G, nodes_df, x[0], x[1])) for x in community_combinations]\n",
    "community_combinations.sort(key=lambda x: x[2], reverse=True)\n",
    "community_combinations = pd.DataFrame(community_combinations, columns=[\"community1\", \"community2\", \"mean_shortest_path\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_combinations = (community_combinations\n",
    "    .assign(random_keywords1=lambda x: x[\"community1\"].map(lambda y: random_keywords_generator(nodes_df, y)))\n",
    "    .assign(random_keywords2=lambda x: x[\"community2\"].map(lambda y: random_keywords_generator(nodes_df, y)))\n",
    "    .assign(random_keywords=lambda x: x[\"random_keywords1\"] + x[\"random_keywords2\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_keywords = community_combinations.sample(1, random_state=42)[\n",
    "    \"random_keywords\"\n",
    "].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords: ['職場友誼', '高齡者', '跨層次分析', '數位轉型策略', '智慧製造', '數位轉型策略']\n",
      "Title:\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Keywords: {random_keywords}\n",
    "Title:\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cmpl-7DvmkHJJMNuFKqMXw9JO0KCzwyjrE', 'object': 'text_completion', 'created': 1683554746, 'model': 'text-davinci-003', 'choices': [{'text': ' 探討職場友誼對高齡者的影響以及數位轉型策略的智慧製造', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 88, 'completion_tokens': 60, 'total_tokens': 148}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "OPENAI_API_KEY = \"\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \" + OPENAI_API_KEY\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"model\": \"text-davinci-003\",\n",
    "    \"prompt\": prompt,\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 256,\n",
    "    \"top_p\": 1,\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"presence_penalty\": 0\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/completions\", headers=headers, json=data)\n",
    "\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keywords: ['職場友誼', '高齡者', '跨層次分析', '數位轉型策略', '智慧製造', '數位轉型策略']\n",
      "result: 探討職場友誼對高齡者的影響以及數位轉型策略的智慧製造\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"keywords: {random_keywords}\\nresult:{response.json()[\"choices\"][0][\"text\"]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BloomForCausalLM, BloomTokenizerFast\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_length = 256\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = BloomTokenizerFast.from_pretrained(\"ckip-joint/bloom-1b1-zh\")\n",
    "model = BloomForCausalLM.from_pretrained(\"ckip-joint/bloom-1b1-zh\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tokenizer.decode(\n",
    "    model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=result_length,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.9,\n",
    "    )[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keywords: ['職場友誼', '高齡者', '跨層次分析', '數位轉型策略', '智慧製造', '數位轉型策略']\n",
      "result:Keywords: ['職場友誼', '高齡者', '跨層次分析', '數位轉型策略', '智慧製造', '數位轉型策略']\n",
      "Title: 整合資訊科技與智慧製造的跨層次分析-以高齡者為例\n",
      "Summary:\n",
      "本文以「跨層次分析」作為研究主題，透過「個案研究法」、「深度訪談法」及「內容分析法」三種研究方法，針對國內某家知名科技製造業，在推動數位轉型時面臨的困難點進行探討，並以「整合資訊科技與智慧製造的跨層次分析」作為研究分析的主軸，透過「個案研究法」、「深度訪談法」及「內容分析法」三種研究方法，透過個案公司內部資訊部門、供應商及員工的跨層次分析，進而探討數位轉型中，其組織架構與資源配置，對高齡者發展數位學習的策略的考量，並提供未來該產業擬定數位學習策略時的重要參考依據。\n",
      "本研究從「數位轉型」的角度，探討目前該產業發展數位學習時，面臨的困難點以及解決的方法。其從個案公司內部資訊部門、供應商\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"keywords: {random_keywords}\\nresult:s{result}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
